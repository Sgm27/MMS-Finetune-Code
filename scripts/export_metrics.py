"""
Script ƒë·ªÉ xu·∫•t training metrics t·ª´ TensorBoard logs ra file JSON
Kh√¥ng c·∫ßn c√†i ƒë·∫∑t TensorBoard - ch·ªâ c·∫ßn tensorflow!
"""

import json
import os
import glob
from pathlib import Path

def export_tensorboard_to_json(log_dir, output_file):
    """
    ƒê·ªçc TensorBoard logs v√† xu·∫•t ra file JSON
    
    Args:
        log_dir: ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a TensorBoard logs
        output_file: T√™n file JSON ƒë·ªÉ l∆∞u k·∫øt qu·∫£
    """
    
    try:
        from tensorboard.backend.event_processing import event_accumulator
    except ImportError:
        print("‚ùå C·∫ßn c√†i ƒë·∫∑t tensorboard: pip install tensorboard")
        return
    
    # T√¨m file event trong log directory
    event_files = glob.glob(os.path.join(log_dir, "**", "events.out.tfevents.*"), recursive=True)
    
    if not event_files:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y TensorBoard event files trong {log_dir}")
        print(f"   ƒê∆∞·ªùng d·∫´n t√¨m ki·∫øm: {log_dir}")
        return
    
    print(f"‚úì T√¨m th·∫•y {len(event_files)} event file(s)")
    
    all_metrics = {
        "training_metrics": {},
        "validation_metrics": {}
    }
    
    for event_file in event_files:
        print(f"ƒêang ƒë·ªçc: {os.path.basename(event_file)}")
        
        try:
            # Load event file v·ªõi tensorboard
            ea = event_accumulator.EventAccumulator(event_file)
            ea.Reload()
            
            # L·∫•y t·∫•t c·∫£ scalar tags
            tags = ea.Tags().get('scalars', [])
            
            for tag in tags:
                events = ea.Scalars(tag)
                
                # Ph√¢n lo·∫°i metrics
                if tag.startswith('train_'):
                    metric_type = "training_metrics"
                elif tag.startswith('val_'):
                    metric_type = "validation_metrics"
                elif tag == 'lr':
                    metric_type = "training_metrics"
                else:
                    metric_type = "training_metrics"
                
                # L∆∞u metrics v·ªõi step v√† value
                if tag not in all_metrics[metric_type]:
                    all_metrics[metric_type][tag] = []
                
                for event in events:
                    all_metrics[metric_type][tag].append({
                        "step": int(event.step),
                        "value": float(event.value)
                    })
        except Exception as e:
            print(f"  ‚ö†Ô∏è  L·ªói khi ƒë·ªçc file: {str(e)}")
            continue
    
    # Ch·ªâ l·∫•y gi√° tr·ªã cu·ªëi c√πng (latest) c·ªßa m·ªói metric
    latest_metrics = {
        "training_metrics": {},
        "validation_metrics": {},
        "step": 0
    }
    
    # T√¨m step cao nh·∫•t
    max_step = 0
    for metric_type in ["training_metrics", "validation_metrics"]:
        for metric_name, values in all_metrics[metric_type].items():
            if values:
                latest = values[-1]
                latest_metrics[metric_type][metric_name] = latest['value']
                max_step = max(max_step, latest['step'])
    
    latest_metrics["step"] = max_step
    
    # L∆∞u ra file JSON (ch·ªâ latest values)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(latest_metrics, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ ƒê√£ xu·∫•t metrics ra file: {output_file}")
    print(f"\nüìä T·ªïng quan metrics:")
    print(f"  - Training metrics: {list(latest_metrics['training_metrics'].keys())}")
    print(f"  - Validation metrics: {list(latest_metrics['validation_metrics'].keys())}")
    print(f"  - Latest step: {latest_metrics['step']}")


def get_latest_metrics_summary(metrics_file):
    """
    ƒê·ªçc file metrics (ƒë√£ l√† latest format)
    """
    with open(metrics_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    step = data.get('step', 0)
    summary = {
        "latest_training_metrics": {},
        "latest_validation_metrics": {}
    }
    
    # Format l·∫°i ƒë·ªÉ hi·ªÉn th·ªã v·ªõi step
    for metric_name, value in data['training_metrics'].items():
        summary['latest_training_metrics'][metric_name] = {
            "step": step,
            "value": value
        }
    
    for metric_name, value in data['validation_metrics'].items():
        summary['latest_validation_metrics'][metric_name] = {
            "step": step,
            "value": value
        }
    
    return summary


if __name__ == "__main__":
    # T·ª± ƒë·ªông t√¨m th∆∞ m·ª•c runs
    log_dir = "runs"
    
    # Ki·ªÉm tra xem th∆∞ m·ª•c log c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(log_dir):
        print(f"‚ö†Ô∏è  Th∆∞ m·ª•c log ch∆∞a t·ªìn t·∫°i: {log_dir}")
        print(f"    Th∆∞ m·ª•c n√†y s·∫Ω ƒë∆∞·ª£c t·∫°o sau khi b·∫Øt ƒë·∫ßu training.")
        print(f"    Vui l√≤ng ch·∫°y l·∫°i script n√†y sau khi training b·∫Øt ƒë·∫ßu.")
    else:
        # Xu·∫•t metrics
        output_file = "training_metrics.json"
        export_tensorboard_to_json(log_dir, output_file)
        
        # In summary
        if os.path.exists(output_file):
            summary = get_latest_metrics_summary(output_file)
            
            print("\n" + "="*60)
            print("üìà LATEST METRICS SUMMARY")
            print("="*60)
            
            print("\nüîπ Training Metrics (Latest):")
            for metric, data in summary['latest_training_metrics'].items():
                print(f"  {metric:30s} = {data['value']:.6f} (step {data['step']})")
            
            if summary['latest_validation_metrics']:
                print("\nüîπ Validation Metrics (Latest):")
                for metric, data in summary['latest_validation_metrics'].items():
                    print(f"  {metric:30s} = {data['value']:.6f} (step {data['step']})")
