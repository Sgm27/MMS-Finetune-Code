"""
Script ƒë·ªÉ xu·∫•t training metrics t·ª´ TensorBoard logs ra file JSON
"""

import json
import os
import glob
from pathlib import Path
from tensorboard.backend.event_processing import event_accumulator

def export_tensorboard_to_json(log_dir, output_file):
    """
    ƒê·ªçc TensorBoard logs v√† xu·∫•t ra file JSON
    
    Args:
        log_dir: ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a TensorBoard logs
        output_file: T√™n file JSON ƒë·ªÉ l∆∞u k·∫øt qu·∫£
    """
    
    # T√¨m file event trong log directory
    event_files = glob.glob(os.path.join(log_dir, "**", "events.out.tfevents.*"), recursive=True)
    
    if not event_files:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y TensorBoard event files trong {log_dir}")
        return
    
    print(f"‚úì T√¨m th·∫•y {len(event_files)} event file(s)")
    
    all_metrics = {
        "training_metrics": {},
        "validation_metrics": {}
    }
    
    for event_file in event_files:
        print(f"ƒêang ƒë·ªçc: {event_file}")
        
        # Load event file
        ea = event_accumulator.EventAccumulator(event_file)
        ea.Reload()
        
        # L·∫•y t·∫•t c·∫£ scalar tags
        tags = ea.Tags()['scalars']
        
        for tag in tags:
            events = ea.Scalars(tag)
            
            # Ph√¢n lo·∫°i metrics
            if tag.startswith('train_'):
                metric_type = "training_metrics"
            elif tag.startswith('val_'):
                metric_type = "validation_metrics"
            elif tag == 'lr':
                metric_type = "training_metrics"
            else:
                metric_type = "training_metrics"
            
            # L∆∞u metrics v·ªõi step v√† value
            if tag not in all_metrics[metric_type]:
                all_metrics[metric_type][tag] = []
            
            for event in events:
                all_metrics[metric_type][tag].append({
                    "step": event.step,
                    "value": float(event.value)
                })
    
    # L∆∞u ra file JSON
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_metrics, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ ƒê√£ xu·∫•t metrics ra file: {output_file}")
    print(f"\nüìä T·ªïng quan metrics:")
    print(f"  - Training metrics: {list(all_metrics['training_metrics'].keys())}")
    print(f"  - Validation metrics: {list(all_metrics['validation_metrics'].keys())}")


def get_latest_metrics_summary(metrics_file):
    """
    L·∫•y gi√° tr·ªã metrics m·ªõi nh·∫•t
    """
    with open(metrics_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    summary = {
        "latest_training_metrics": {},
        "latest_validation_metrics": {}
    }
    
    # L·∫•y gi√° tr·ªã cu·ªëi c√πng c·ªßa m·ªói metric
    for metric_name, values in data['training_metrics'].items():
        if values:
            latest = values[-1]
            summary['latest_training_metrics'][metric_name] = {
                "step": latest['step'],
                "value": latest['value']
            }
    
    for metric_name, values in data['validation_metrics'].items():
        if values:
            latest = values[-1]
            summary['latest_validation_metrics'][metric_name] = {
                "step": latest['step'],
                "value": latest['value']
            }
    
    return summary


if __name__ == "__main__":
    # C·∫•u h√¨nh
    config_file = "training_config_examples/finetune_mms_vie.json"
    
    # ƒê·ªçc config ƒë·ªÉ l·∫•y output_dir
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        output_dir = config.get('output_dir', '/vits_finetuned_vie')
        
        # N·∫øu l√† ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi ho·∫∑c b·∫Øt ƒë·∫ßu b·∫±ng /, coi nh∆∞ l√† th∆∞ m·ª•c local
        if output_dir.startswith('/'):
            output_dir = output_dir.lstrip('/')
        
        log_dir = os.path.join(output_dir, "runs")
    else:
        # M·∫∑c ƒë·ªãnh
        output_dir = "vits_finetuned_vie"
        log_dir = os.path.join(output_dir, "runs")
    
    # Ki·ªÉm tra xem th∆∞ m·ª•c log c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(log_dir):
        print(f"‚ö†Ô∏è  Th∆∞ m·ª•c log ch∆∞a t·ªìn t·∫°i: {log_dir}")
        print(f"    Th∆∞ m·ª•c n√†y s·∫Ω ƒë∆∞·ª£c t·∫°o sau khi b·∫Øt ƒë·∫ßu training.")
        print(f"    Vui l√≤ng ch·∫°y l·∫°i script n√†y sau khi training b·∫Øt ƒë·∫ßu.")
    else:
        # Xu·∫•t metrics
        output_file = "training_metrics.json"
        export_tensorboard_to_json(log_dir, output_file)
        
        # In summary
        if os.path.exists(output_file):
            summary = get_latest_metrics_summary(output_file)
            
            print("\n" + "="*60)
            print("üìà LATEST METRICS SUMMARY")
            print("="*60)
            
            print("\nüîπ Training Metrics (Latest):")
            for metric, data in summary['latest_training_metrics'].items():
                print(f"  {metric:30s} = {data['value']:.6f} (step {data['step']})")
            
            if summary['latest_validation_metrics']:
                print("\nüîπ Validation Metrics (Latest):")
                for metric, data in summary['latest_validation_metrics'].items():
                    print(f"  {metric:30s} = {data['value']:.6f} (step {data['step']})")
